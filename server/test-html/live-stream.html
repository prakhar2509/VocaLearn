<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>🎙️ VoiceStudy Live Streaming</title>
    <style>
      body {
        font-family: sans-serif;
        padding: 20px;
      }
      button {
        margin-right: 10px;
        padding: 10px 20px;
      }
      #status {
        margin-top: 10px;
        font-weight: bold;
      }
      h2 {
        margin-top: 30px;
      }
      p {
        background: #f0f0f0;
        padding: 10px;
        border-radius: 5px;
      }
    </style>
  </head>
  <body>
    <h1>🎙️ VoiceStudy: Live Audio Stream</h1>

    <div style="margin: 20px 0; padding: 15px; background: #f8f9fa; border-radius: 5px;">
      <h3>📚 Language Settings</h3>
      <label for="learningLang">Learning Language:</label>
      <select id="learningLang" style="margin: 0 10px; padding: 5px;">
        <option value="es-ES">Spanish</option>
        <option value="fr-FR">French</option>
        <option value="en-US">English</option>
        <option value="hi-IN" selected>Hindi</option>
        <option value="ja-JP">Japanese</option>
        <option value="it-IT">Italian</option>
        <option value="de-DE">German</option>
      </select>
      
      <label for="nativeLang">Native Language:</label>
      <select id="nativeLang" style="margin: 0 10px; padding: 5px;">
        <option value="en-US" selected>English</option>
        <option value="es-ES">Spanish</option>
        <option value="fr-FR">French</option>
        <option value="hi-IN">Hindi</option>
        <option value="jp-JP">Japanese</option>
        <option value="it-IT">Italian</option>
        <option value="de-DE">German</option>
      </select>
      
      <label for="mode">Mode:</label>
      <select id="mode" style="margin: 0 10px; padding: 5px;">
        <option value="dialogue" selected>Dialogue</option>
        <option value="echo">Echo</option>
      </select>
    </div>

    <button id="start">Start Streaming</button>
    <button id="stop" disabled>Stop Streaming</button>
    <p id="status">🔴 Not connected</p>

    <h2>📝 Transcription:</h2>
    <p id="transcription">–</p>

    <h2>✏️ Correction:</h2>
    <p id="correction">–</p>

    <h2>📚 Explanation:</h2>
    <p id="explanation">–</p>

    <script type="module">
      const startBtn = document.getElementById("start");
      const stopBtn = document.getElementById("stop");
      const status = document.getElementById("status");
      const learningLang = document.getElementById("learningLang");
      const nativeLang = document.getElementById("nativeLang");
      const mode = document.getElementById("mode");

      let ws;
      let audioCtx;
      let workletNode;
      let audioStream;

      function getWsUrl() {
        const learning = learningLang.value;
        const native = nativeLang.value;
        const selectedMode = mode.value;
        return `ws://localhost:4001?learningLanguage=${learning}&nativeLanguage=${native}&mode=${selectedMode}`;
      }

      let gotTranscription = false;
      let gotCorrection = false;
      let gotExplanation = false;
      let gotAudioCorrection = false;
      let gotAudioExplanation = false;

      startBtn.onclick = async () => {
        ws = new WebSocket(getWsUrl());

        ws.binaryType = "arraybuffer";

        ws.onopen = async () => {
          status.textContent = "🟢 Connected and streaming...";

          audioStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
            },
          });

          audioCtx = new AudioContext({ sampleRate: 16000 });

          await audioCtx.audioWorklet.addModule(
            URL.createObjectURL(
              new Blob(
                [
                  `
          class PCMWorkletProcessor extends AudioWorkletProcessor {
            process(inputs) {
              const input = inputs[0][0];
              if (!input) return true;
              const buffer = new ArrayBuffer(input.length * 2);
              const view = new DataView(buffer);
              for (let i = 0; i < input.length; i++) {
                let sample = Math.max(-1, Math.min(1, input[i]));
                sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                view.setInt16(i * 2, sample, true);
              }
              this.port.postMessage(buffer);
              return true;
            }
          }
          registerProcessor('pcm-worklet', PCMWorkletProcessor);
        `,
                ],
                { type: "application/javascript" }
              )
            )
          );

          const source = audioCtx.createMediaStreamSource(audioStream);
          workletNode = new AudioWorkletNode(audioCtx, "pcm-worklet");

          workletNode.port.onmessage = (event) => {
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(event.data);
            }
          };

          source.connect(workletNode).connect(audioCtx.destination);

          startBtn.disabled = true;
          stopBtn.disabled = false;
        };

        ws.onmessage = (msg) => {
          const data = JSON.parse(msg.data);
          console.log("📨 Message from server:", data);

          if (data.transcription) {
            document.getElementById("transcription").textContent =
              data.transcription;
          }

          if (data.correction) {
            document.getElementById("correction").textContent = data.correction;
          }

          if (data.explanation) {
            document.getElementById("explanation").textContent =
              data.explanation;
          }

          if (data.type === "done" && data.done) {
            const playAudio = (url) =>
              new Promise((resolve, reject) => {
                const audio = new Audio(url);
                audio.onended = resolve;
                audio.onerror = reject;
                audio.play();
              });

            const playAndClose = async () => {
              try {
                if (data.audioCorrectionUrl) {
                  await playAudio(data.audioCorrectionUrl);
                  console.log("🔊 Correction audio finished.");
                }

                if (data.audioExplanationUrl) {
                  await playAudio(data.audioExplanationUrl);
                  console.log("🔊 Explanation audio finished.");
                }

                ws.close(); // ✅ Close WebSocket only after both audios played
                status.textContent = "✅ Finished and connection closed.";
              } catch (err) {
                console.error("❌ Audio playback failed:", err);
                status.textContent = "⚠️ Audio playback error.";
                ws.close(); // Still close on error to avoid hanging connection
              }
            };

            playAndClose();
          }

          if (data.error) {
            status.textContent = "⚠️ Error: " + data.error;
            console.error("❌ Server error:", data.error);
          }
        };

        ws.onerror = (err) => {
          console.error("❌ WebSocket error:", err);
          status.textContent = "⚠️ WebSocket error";
        };
      };

      stopBtn.onclick = () => {
        audioStream.getTracks().forEach((track) => track.stop());
        ws.send(JSON.stringify({ end: true }));
        status.textContent = "🟡 Awaiting server response...";
        stopBtn.disabled = true;
      };
    </script>
  </body>
</html>
